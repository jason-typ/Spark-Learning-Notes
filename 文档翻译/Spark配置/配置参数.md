# 常用配置参数


## Execution Behavior
- `spark.default.parallelism`
  - **意义**：没有显式配置时，Shuffle操作(如join、reduceByKey等)或`parallelize`函数(没有父RDD)返回的RDD中，包含的默认分区数
  - **默认值**：对于Shuffle操作(例如`reduceByKey`)来说，取父RDD最大的分区数；对于`parallelize`这种没有父RDD的操作，会根据cluster manager的不同而有所区别：
    - Local Mode，本机上给的core的数量
    - Mesos细粒度模式，8个
    - 其他，max(所有Executor中包含的core的总数，2)
- `spark.executor.cores`
  - **意义**：每个executor中使用的core的数量
  - **默认值**：不同资源管理器下有所不同
    - YARN，1个
    - Standalone或粗粒度Mesos下，worker节点上所有可用的core的数量


The number of cores to use on each executor. In standalone and Mesos coarse-grained modes, for more detail, see this description.
## SparkStreaming

- `spark.streaming.blockInterval`
  - **意义**：SparkStreaming接收器对接收到的数据，在将数据保存到Spark内存前，以多久的时间间隔将数据组成一个block。一个Block就对应这个batch中Partition的数目，从而对应如map的task的数目(处理的并行度)
  - **默认值**：默认200ms，(建议)最低不低于50ms

## Compression and Serialization
- `spark.rdd.compress`
  - **意义**：是否需要压缩序列化的RDD(分区)。能够以一定的CPU为代价，降低内存的消耗。默认使用的压缩方式是`spark.io.compression.codec`
  - **默认值**：false

## Scheduling
- `spark.cores.max`
  - **意义**：在Standalone或粗粒度Mesos下，应用程序可以从整个集群(非单个机器)中申请的最大的core的数量
  - **默认值**
    - Standalone模式下，默认为`spark.deploy.defaultCores`
    - Mesos下，所有可用的节点
- `spark.locality.wait`
  - **意义**，为执行数据本地化任务，在将本地化级别降低前所等待的时间段。各个本地化级别之间等待的时间长度都用这个值，但也可以为每个本地化等待的时间配置自己各自独特的值(下面几个参数)。如果任务执行时间过长，并且本地化性能差，那么应该调大这个值。不过这个默认值一般都可以工作的很好
  - **默认值**，3s
- `spark.locality.wait.process`
  - **意义**，为执行进程本地化，所可以等待的时间
  - **默认值**，使用`spark.locality.wait`设置的值
- `spark.locality.wait.node`
  - **意义**，为执行节点本地化，所可以等待的时间
  - **默认值**，使用`spark.locality.wait`设置的值
- `spark.locality.wait.rack`
  - **意义**，为执行机架本地化，所可以等待的时间
  - **默认值**，使用`spark.locality.wait`设置的值
