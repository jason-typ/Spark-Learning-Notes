1. spark.executor.memory

这个参数决定了每个Executor可用的内存大小。默认是0.6。官方文档建议这个值不要超过JVM Old Gen区域的比例。因为RDD Cache都是长期保存在内存中的，也就是最终会被移到Old Gen区域。如果这部分的内存设置的过大，会导致Old Gen区域过小，Old Gen区域被占满后，会导致频繁的全量的垃圾回收。

因此如果频繁的发生垃圾回收，可以考虑降低这个值。当RDD Cache可以用到的内存空间不够时，会把多余的数据缓存到硬盘上。这样虽然会有一定的性能损失，但减少了全量的垃圾回收，腾出更多内存空间用于执行任务，反而能提高程序的整体性能。

2. spark.local.dir

  可以配置多个磁盘路径，以增加磁盘IO的带宽。
