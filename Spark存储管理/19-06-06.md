- BlockManagerMasterEndpoint
  只存在于Master节点上，由Driver上的SparkEnv负责创建和注册到Driver的RpcEnv中。负责管理所有节点上的BlockManager，包括BlockManager与Executor的映射关系，以及Block的位置信息(即Block所在的BlockManager)等。
  Driver或Executor上`BlockManagerMaster`的`driverEndpoint`属性将持有`BlockManagerMasterEndpoint`的`RpcEndpointRef`，用于RPC通信。
- BlockManagerSlaveEndpoint
  每个Executor和Driver都有属于自己的BlockManagerSlaveEndpoint，分别由各自的SparkEnv负责创建和注册到各自的RpcEnv中。
  `BlockManagerSlaveEndpoint`接收来自于`BlockManagerMasterEndpoint`发来的命令。`BlockManagerSlaveEndpoint`在`BlockManager`中包裹在属性`slaveEndpoint`中
  在向Driver注册BlockManager时，会带上`BlockManagerSlaveEndpoint`的信息：
  ```Scala
  val idFromMaster = master.registerBlockManager(id, maxOnHeapMemory, maxOffHeapMemory, slaveEndpoint)
  ```
- BlockManagerMaster
  代理BlockManager与Driver上的BlockManagerMasterEndpoint通信。其本身并不是分布式的Master，而只是用于与Master进行通信。Driver和Executor上都会有一个BlockManagerMaster。

### BlockManagerMasterEndpoint
`BlockManagerMasterEndpoint`负责管理各个节点上的`BlockManager`。

#### 1. 创建过程
`BlockManagerMasterEndpoint`只会在Driver端创建一个，在Driver的SparkEnv中创建，可以看到创建过程：

```Scala
val blockManagerMaster = new BlockManagerMaster(registerOrLookupEndpoint(
  BlockManagerMaster.DRIVER_ENDPOINT_NAME,
  new BlockManagerMasterEndpoint(rpcEnv, isLocal, conf, listenerBus)),
  conf, isDriver)
```

其中，`registrOrLookupEndpoint`方法如下：
```Scala
def registerOrLookupEndpoint(name: String, endpointCreator: => RpcEndpoint): RpcEndpointRef = {
  if (isDriver) {
    rpcEnv.setupEndpoint(name, endpointCreator)
  } else {
    RpcUtils.makeDriverRef(name, conf, rpcEnv)
  }
}
```

如果当前节点是Driver，那么就会使用提供的函数创建一个`RpcEndpoint`，并注册到`rpcEnv`中；如果当前是Executor，那么就直接获取这个`RpcEndpointRef`。最终，无论是Driver还是Executor的`BlockManagerMaster`中，都会保存有这个`BlockManagerMasterEndpoint`的`RpcEndpointRef`。

#### 2. 功能
BlockManagerMasterEndpoint负责各个节点上BlockManager的管理等，响应来自`BlockManager`的请求。几个主要的成员变量有：
- `blockManagerInfo: HashMap[BlockManagerId, BlockManagerInfo]`
  block manager id到block manager information的映射关系
- `blockManagerIdByExecutor: HashMap[String, BlockManagerId]`
  executor ID到block manager id的映射关系
- `blockLocations: JHashMap[BlockId, HashSet[BlockManagerId]]`
  block id到持有这些block的block manager的映射关系

函数`receiveAndReply`定义了`BlockManagerMasterEndpoint`支持的功能，包括：
- `RegisterBlockManager`
  接收`BlockManager`的注册
- `GetLocations`
  获取某个BlockId的位置信息
- ...

### BlockManagerMaster
代理BlockManager与Driver上的BlockManagerMasterEndpoint通信。其本身并不是分布式的Master，而只是用于与Master进行通信。

BlockManagerMaster在Driver和每个Executor中都有一个。在`SparkEnv`中创建：
```Scala
val blockManagerMaster = new BlockManagerMaster(registerOrLookupEndpoint(
  BlockManagerMaster.DRIVER_ENDPOINT_NAME,
  new BlockManagerMasterEndpoint(rpcEnv, isLocal, conf, listenerBus)),
  conf, isDriver)
```

`BlockManagerMaster`保存有运行在Driver端的`BlockManagerMasterEndpoint`的`RpcEndpointRef`，用于RPC请求。比如，在`BlockManager`初始化过程中，需要到Driver端注册自己：
```Scala
val idFromMaster = master.registerBlockManager(
  id,
  maxOnHeapMemory,
  maxOffHeapMemory,
  slaveEndpoint)
```
其中`master: BlockManagerMaster`的`registerBlockManager`方法如下：
```Scala
val updatedId = driverEndpoint.askSync[BlockManagerId](
    RegisterBlockManager(blockManagerId, maxOnHeapMemSize, maxOffHeapMemSize, slaveEndpoint))
```
其中的`driverEndpoint`就是`BlockManagerMaster`创建过程中，传入的`BlockManagerMasterEndpoint`的RPC引用。`BlockManagerMasterEndpoint`在方法`receiveAndReply`中定义了收到请求后的响应：
```Scala
case RegisterBlockManager(blockManagerId, maxOnHeapMemSize, maxOffHeapMemSize, slaveEndpoint) =>
    context.reply(register(blockManagerId, maxOnHeapMemSize, maxOffHeapMemSize, slaveEndpoint))
```

`BlockManagerMaster`提供的几种RPC的功能有：
- 删除一个死掉的Executor(只会在Driver端发起这个请求)
- `registerBlockManager`，向Driver注册BlockManager
- `updateBlockInfo`，更新block信息
- `getLocations`，向Driver询问某个blociId的位置
- ...


### BlockManagerSlaveEndpoint
Spark中的Block存储也是分布式的，`BlockManagerSlaveEndpoint`是Block存储中的Slave节点，Master节点是上面介绍的`BlockManagerMasterEndpoint`。`BlockManagerSlaveEndpoint`负责接收来自`BlockManagerMasterEndpoint`的RPC请求。

上面介绍的`BlockManagerMaster`保存有`BlockManagerMasterEndpoint`的RPC引用，用于`BlockManager`**发起RPC请求**到`BlockManagerMasterEndpoint`。而`BlockManagerSlaveEndpoint`则是用来**接收RPC请求**，请求来自`BlockManagerMasterEndpoint`。

每个Executor和Driver的`Blockmanager`中都有属于自己的`BlockManagerSlaveEndpoint`，包裹在`BlockManager`的成员变量`slaveEndpoint`中：
```
private val slaveEndpoint = rpcEnv.setupEndpoint(
  "BlockManagerEndpoint" + BlockManager.ID_GENERATOR.next,
  new BlockManagerSlaveEndpoint(rpcEnv, this, mapOutputTracker))
```

在向Driver注册BlockManager时，会带上`BlockManagerSlaveEndpoint`的信息：
```Scala
val idFromMaster = master.registerBlockManager(id, maxOnHeapMemory, maxOffHeapMemory, slaveEndpoint)
```
这样，`BlockManager`就可以使用`SlaveEndpoint`接收来自`BlockManagerMasterEndpoint`的RPC请求


***

Spark中存放数据的单元是Block，一个Block对应RDD中的一个Partition。每个Block由唯一的BlockID标识，格式为`"rdd_"+"rddId"+"_"+partitionId`。如下图所示。

![RDD的Partition与Block之间的逻辑关系](images/2019/06/rdd的partition与block之间的逻辑关系.png)


BlockManager运行在Driver和每个Executor上。运行在Driver上的BlockManager负责整个Application的Block的管理工作；运行在Executor上的BlockManager负责管理该Executor上的Block，并向Driver的BlockManager汇报Block的信息和接收它的命令。
