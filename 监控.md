
### 1. 监控级别
对Spark的监控可以分为以下几个级别：
- Spark应用程序
  无论是debug还是进一步查看程序的运行，首先要查看的是Spark的UI以及运行日志，从而能得到应用程序以Spark中的某些概念级别(如RDD、query plan等)的运行信息。
- JVM级别
  Spark中各个executor在各自独立的JVM中运行。因此为了更一步了解代码的运行状态，可以对各个JVM的状态进行监控。一些JVM应用，如`jstack`可以提供堆栈跟踪信息，`jmap`可以查看堆存储信息，`jstat`用来按时间报告统计数据等。
- 系统层面
  JVM运行在OS上，也有必要在机器层面进行监控，保证机器的正常运行。包括CPU、内存、IO、网络等信息。
- 集群层面
  Spark一般是运行在一个集群上的，由资源管理器进行调度，如YARN、Mesos。因此，也有必要对集群整体的运行状况进行监控



### 2. Spark中的监控
Spark应用程序有多种监控方式，包括webUI、metrics以及一些外部工具。
### 2.1. Web Interfaces
每个SparkContext都会启动一个web UI，默认在4040端口上，提供了Application以及Spark工作负载级别的一些监控信息。如下图：
![SparkWebUI](images/2019/03/sparkwebui.png)

这个页面只有在程序运行期间才有效。如果想要在程序结束后还能够查看到该Application的信息，需要配置启用历史服务器

### 2.2 历史服务器
Application在运行结束后，在4040端口上提供的WebUI也就失效了。如果想要在Application运行结束后仍然能够查看到，需要启用Spark的历史服务器。

启用历史服务器需要几个配置。首先需要Application将日志记录到某个指定位置，然后HistoryServer能够从这个位置读取数据。具体查看《Spark配置.md》。

### 3. REST API


#### 4. 度量
Spark有一套基于[Dropwizard Metrics Library](https://metrics.dropwizard.io/4.0.0/)的可配置的度量系统。这套系统允许将Spark的度量信息汇报到各种类型的sink，如HTTP、JMX、CSV文件等。度量系统由配置文件`metrics.properties`配置。关于文件的位置，要么使用Spark自带的默认的配置路径下的，要么可以通过配置参数`spark.metrics.conf`指定自定义的度量配置文件的位置。

默认情况下，度量信息的根命名空间是Application ID，由`spark.app.id`指定。当Application重启之后，ID自然也就变了。但更多时候，我们想要的是一套代码(一个业务线)在时间线上所有的运行情况，而不是按照Application ID分为几个不同的部分。这种情况下，可以使用配置选项`spark.metircs.namespace`来自定义namespace。比如设定为app的名称：`${spark.app.name}`。

对于与Driver或Executor无关的度量信息，不会被放到`spark.app.id`或`spark.metrics.namespace`属性所指定的命名空间中。

Spark的度量系统分为多个子实例，各自对应Spark内部的不同组件。并且支持为每个instance配置其各自的零到多个Sink。目前的度量系统支持的子实例包括：
- master：master进程
- application：
- worker
- executor
- driver
- shuffleService
- applicationMaster

Spark内置的支持的Sink包含在`org.apache.spark.metrics.sink`包中，其中有：
- ConsoleSink
- CSVSink
- JmxSink
- MetricsServlet
- GraphiteSink
- Slf4jSink
- StatsdSink

当然还可以配置自己需要的Sink，如[Prometheus](https://github.com/banzaicloud/spark-metrics)

#### 5. 高级工具
