## 加载/保存函数


### 加载文件
加载文件有固定的格式：使用`format`函数指定文件的类型，然后使用`load`函数指定文件的路径：

```scala
val peopleDF = spark.read.format("json").load("examples/src/main/resources/people.json")
```

`format`没有指定时，默认是parquet类型。上面的方式可以简化为：

```scala
val peopleDF = spark.read.json("examples/src/main/resources/people.json")
```

### 保存文件

保存文件也有固定的格式：使用`format`指定类型，使用`save`保存到指定路径

```
usersDF.write.format("orc")
  .option("orc.bloom.filter.columns", "favorite_color")
  .option("orc.dictionary.key.threshold", "1.0")
  .save("users_with_options.orc")
```

### 其他选项

加载与保存文件都可以使用`option`指定其他的选项。[参考](https://spark.apache.org/docs/latest/sql-data-sources-load-save-functions.html)
