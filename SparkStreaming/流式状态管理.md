[参考](http://sharkdtu.com/posts/spark-streaming-state.html)

## Spark Streaming状态管理
在流式数据中，我们有时需要维护某个状态。比如我司要统计某个用户的行为，打点数据不断的过来，我们需要知道用户何时开始一个新的session，session中做了什么，session什么时候结束等。这就要求我们维护一个session的状态，并能够在一段时间内没有用户数据时自动结束掉session。

Spark Streaming为状态管理提供了两种方法：
1. **updateStateByKey**
  Spark Streaming是基于微批进行处理的，每个micro-batch都会形成一个RDD传入Spark进行处理。因此，最直接的方法就是：当前batch形成的RDD与之前的计算结果RDD进行聚合，产生一个新的RDD。这种方法很直接，但是效率较低，因为每个批次处理结束后都需要与之前维护的状态RDD完成聚合操作，在数据量不断增大的情况下，效率会越来越低。
2. **mapWithState**
  由于RDD是不可变的数据集合，因此在Spark1.6之后提供了`MapWithStateRDDRecord`这一可变集合，并放到`MapWithStateRDD`中。用`MapWithStateRDDRecord`维护所有key的状态。

下面介绍具体的使用方法，还是以wordcount为例，数据的准备代码如下。从localhost的9999端口接收socket数据，并将收到的数据按单词进行拆分后形成键值对RDD。

```Scala
val sparkConf = new SparkConf()
  .setAppName("StatefulNetworkWordCount")
  .setMaster("local[2]")
// Create the context with a 2 second batch size
val ssc = new StreamingContext(sparkConf, Seconds(2))
ssc.checkpoint(".")

// Initial state RDD for mapWithState operation
val initialRDD = ssc.sparkContext.parallelize(List(("hello", 1), ("world", 1)))

// Create a ReceiverInputDStream on target ip:port and count the
// words in input stream of \n delimited test (eg. generated by 'nc')
val lines = ssc.socketTextStream("localhost", 9999)
val wordDstream = lines.flatMap(_.split(" ")).map { word => (word, 1) }
```

### updateStateByKey
先上实现：
```
val updateStateFun = (values: Seq[Int], state: Option[Int]) => {
   val currentBatchWordCount = values.foldLeft(0)(_ + _)
   val lastStateWordCount = state.getOrElse(0)
   Some(currentBatchWordCount + lastStateWordCount)
 }

val stateDStream = wordDstream.updateStateByKey(updateStateFun)
stateDStream.print()
```

`updateStateByKey`接收一个状态更新函数。SparkStreaming会使用这个更新函数，在每个batch interval中更新内部维护的状态。这个更新函数的类型为：

```
updateFunc: (Seq[V], Option[S]) => Option[S]
```
第一个参数是当前批次中某个key对应的所有value的序列，第二个参数是该key的历史状态信息。整个更新流程如下：
![updateStateByKey更新流程](/images/2019/02/updatestatebykey更新流程.png)

图中左边蓝色箭头为实时过来的数据流，即代码中的`wordDstream`。在一个新的batch job中，Spark会将当前批次(`rdd(x)`)与前一个批次生成的状态(`state(x-1)`)做`cogroup`操作。`cogroup`中的更新操作就是我们定义的方法`updateStateFun`。通过这种方法，在每个batch interval中，都会更新一次维护的状态。

不过`updateStateByKey`方法有一个问题就是每次都是在`state`上执行全量的更新操作，即使新过来的batch中没有state中已经维护的某个key的状态，状态更新函数仍会在state中的这个key上执行一遍。比如，state中维护了'hello'这个单词出现的次数为3，但是下一个batch中没有'hello'这个单词，但是这个更新函数仍然会在state中的'hello'上执行一遍。因此，加入state随着时间不断的增大，在做`cogroup`时就会越来越慢，导致性能的下降。

### mapWithState
从Spark1.6开始，引入了一种全新的状态管理机制`mapWithState`，可以解决`updateStateByKey`一直全量更新的操作。

【**作用**】
将用户定义的function作用在流中的每个key-value元素对上，并为每个key维护某种状态，返回类型为`[[MapWithStateDStream]]`。
```Scala
def mapWithState[StateType: ClassTag, MappedType: ClassTag](
      spec: StateSpec[K, V, StateType, MappedType]
    ): MapWithStateDStream[K, V, StateType, MappedType]
```
【**基本使用**】
接收一个`StateSpec`类型，这个`StateSpec`类型的作用是将提供的function进行包裹。比如一个WordCount计数的程序：
```Scala
val stateSpec = StateSpec.function {
  (key: String, value: Option[Int], state: State[Int]) =>
    val sum = value.getOrElse(0) + state.getOption.getOrElse(0)
    state.update(sum)
    (word, sum)
}
```
对比上面的作用介绍，key是key-value对中的键，value是key-value对中的值，state是我们想要为key维护的对应到状态使用`State`进行的包裹。整个function的作用就是基于当前传过来的key-value对，对维护的状态进行更新。

Spark内部的执行流程为：
![mapWithState执行流程](/images/2019/02/mapwithstate执行流程.png)

基本原理仍是使用当前batch中的数据更新Spark中维护的状态，不同的是只会使用当前batch中存在的key去更新state，因而可以看做是一个增量操作。具体的更新过程如下图：
![具体更新过程](images/2019/02/具体更新过程.png)

内存中维护的state会进行分区，默认使用的是`HashPartitioner`，分区数是默认的并行度
```
private val partitioner = spec.getPartitioner().getOrElse(
new HashPartitioner(ssc.sc.defaultParallelism))
```
一个新的batch里的数据到来，同样会将数据进行分区。state与batch使用相同的分区，这样使得相同的键被分到相同的分区中。拥有相同的分区划分意味着拥有相同键的新的数据以及state中维护的数据，会被分配到同一个机器上。之后，state更新函数就会在每个partition上执行。state数据的保存使用hashmap，在每个分区中，会遍历新的数据的key，并更新或增加state中对应的key，并返回新的state。(具体的代码都在MapWithStateRDD.scala中，我也只是大致浏览了下，代码与之前理解的大致讲得通)

【**其他设置**】
`StateSpec`封装了用户逻辑(function)，还提供了其他的设置，如初始状态、超时时间：

```Scala
// 代码参考源码中JavaStatefulNetworkWordCount
val initialRDD = ssc.sparkContext.parallelize(List(("hello", 1), ("world", 1)))
val stateSpec =
  StateSpec
    .function {
      (key: String, value: Option[Int], state: State[Int]) =>
      val sum = value.getOrElse(0) + state.getOption.getOrElse(0)
      state.update(sum)
      (word, sum)
    }
    .timeout(Seconds(60))
    .initialState(initialRDD)
```
超时时间是指：如果一段时间内没有收到某个key的数据，则停止对该key状态的维护并删除。在删除后如果重新收到该key的数据，会重新生成一个新的state，并进行维护。超时时间可以用来维护session的状态，超过一定时间将session自动结束。但这个时间有时候会很不准。

初始状态是指：在处理流数据之前，状态的初始值。

【**源码分析**】

【**问题**】
看原文章中讲的，`mapWithState`对内存的占用过大，并且一些实现也不是很友好。我司目前的数据量很小，暂时没发现什么问题。不过偶尔会看到`block locks were not released`的log，但是用起来没什么事儿。暂时先不管。

### 使用Redis管理状态

暂时数据量小到不会用到，[参考](http://sharkdtu.com/posts/spark-streaming-state.html)
